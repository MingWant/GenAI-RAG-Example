{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ea979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#安装Environment\n",
    "!pip install langchain chromadb sentence-transformers pypdf openai tiktoken langchain_community langchain_text_splitters langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286cf01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import OpenAI  # 或 HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 1. Load本地知識庫 (Replace with your own knowledge base)\n",
    "loader = TextLoader(\"./knowledge.txt\")  # 假設有一個名為 knowledge.txt 的文件\n",
    "documents = loader.load()\n",
    "\n",
    "custom_prompt = PromptTemplate(\n",
    "    template=\"\"\"請基於以下上下文回答問題。如果上下文不包含答案，請運用你的常識回答：\n",
    "    \n",
    "    上下文：\n",
    "    {context}\n",
    "    問題：{question}\n",
    "    答案：\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "\n",
    "# 2. 拆分文本為段落\n",
    "# 使用 RecursiveCharacterTextSplitter 來將文檔拆分為更小的段落，以便於向量化和檢索\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # 每段文本長度\n",
    "    chunk_overlap=50  # 段落重疊長度\n",
    ")\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3. 創建向量數據庫\n",
    "# 使用 SentenceTransformerEmbeddings 將文本轉換為向量\n",
    "embedding_model = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=texts,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./rag_db\"  # 本地儲存的Path\n",
    ")\n",
    "\n",
    "# 4. Setup檢索器\n",
    "# 使用最大邊際相關性搜索 (MMR) 或相似度閾值檢索\n",
    "# 這裡選擇 MMR 搜索，返回最相關的片段\n",
    "retriever = vector_db.as_retriever(\n",
    "    search_type=\"mmr\",  # 最大边际相关性搜索\n",
    "    search_kwargs={\n",
    "        \"k\": 5  # 返回最相關的5個片段\n",
    "    }\n",
    ")\n",
    "\n",
    "# 5. 配置 LLM\n",
    "# 這裡可以選擇使用 OpenAI 的 GPT 模型或開源\n",
    "## 選項A: 使用OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "        api_key= '你的API密鑰',  # 替換為你的OpenAI API密鑰\n",
    "        temperature=0.7,  # 控制生成文本的隨機性\n",
    "        model = '模型名稱',  # 替換為你想使用的模型名稱，如 'gpt-3.5-turbo'\n",
    "        max_tokens=1000,  # 控制生成文本的最大長度\n",
    "        base_url = 'base_url'  # 替換為你的OpenAI API基礎URL，如果使用自定義部署\n",
    "    )\n",
    "\n",
    "## 選項B: 使用 HuggingFace 的 LLM\n",
    "# from langchain_community.llms import HuggingFacePipeline\n",
    "# from langchain_community.llms import HuggingFaceHub\n",
    "# llm = HuggingFaceHub(repo_id=\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "\n",
    "\n",
    "# 6. 創建RAG Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # 簡單拼接檢索結果\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": custom_prompt}  # 應用自定義Prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85140551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 提問測試\n",
    "query = \"說明一下地球的基本信息\"\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(f\"答案：{result['result']}\")\n",
    "print(\"\\nDoc來源：\")\n",
    "for doc in result['source_documents']:\n",
    "    print(f\"- {doc.metadata['source']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
